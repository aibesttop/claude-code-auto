"""
Validation Diagnostic Tool

å¸®åŠ©è¯Šæ–­ä¸ºä»€ä¹ˆéªŒè¯å¤±è´¥
"""

import re
from pathlib import Path


def diagnose_file(file_path: str, required_sections: list):
    """è¯Šæ–­æ–‡ä»¶éªŒè¯é—®é¢˜"""
    
    print("=" * 70)
    print(f"ğŸ” è¯Šæ–­æ–‡ä»¶: {file_path}")
    print("=" * 70)
    
    path = Path(file_path)
    
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not path.exists():
        print(f"\nâŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        print(f"   å½“å‰å·¥ä½œç›®å½•: {Path.cwd()}")
        print(f"   ç»å¯¹è·¯å¾„: {path.absolute()}")
        
        # å°è¯•æŸ¥æ‰¾æ–‡ä»¶
        parent = path.parent
        if parent.exists():
            print(f"\nğŸ“ çˆ¶ç›®å½•å­˜åœ¨ï¼Œå†…å®¹:")
            for item in parent.iterdir():
                print(f"   - {item.name}")
        return
    
    print(f"âœ… æ–‡ä»¶å­˜åœ¨\n")
    
    # 2. è¯»å–æ–‡ä»¶å†…å®¹
    try:
        content = path.read_text(encoding='utf-8')
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
        print(f"ğŸ“Š æ–‡ä»¶è¡Œæ•°: {len(content.splitlines())} è¡Œ\n")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # 3. æå–æ‰€æœ‰headers
    all_headers = re.findall(r'^(#{1,6})\s+(.+)$', content, re.MULTILINE)
    
    print(f"ğŸ“ æ‰¾åˆ° {len(all_headers)} ä¸ªheaders:\n")
    for level, title in all_headers[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ª
        print(f"   {level} {title}")
    
    if len(all_headers) > 20:
        print(f"   ... (è¿˜æœ‰ {len(all_headers) - 20} ä¸ª)")
    
    print("\n" + "-" * 70)
    
    # 4. æ£€æŸ¥æ¯ä¸ªrequired section
    print(f"\nğŸ¯ éªŒè¯Required Sections:\n")
    
    for required in required_sections:
        print(f"Required: '{required}'")
        
        # Method 1: ç²¾ç¡®åŒ¹é…
        if required in content:
            print(f"   âœ… Method 1 (ç²¾ç¡®åŒ¹é…): Found")
            continue
        
        # Method 2: çµæ´»ç©ºæ ¼
        pattern = re.escape(required)
        pattern = pattern.replace(r'\ ', r'\s*')
        
        if re.search(pattern, content, re.MULTILINE):
            print(f"   âœ… Method 2 (çµæ´»ç©ºæ ¼): Found with pattern {pattern}")
            continue
        
        # Method 3: å½’ä¸€åŒ–
        normalized_required = ' '.join(required.split())
        normalized_content = ' '.join(content.split())
        
        if normalized_required in normalized_content:
            print(f"   âœ… Method 3 (å½’ä¸€åŒ–): Found")
            continue
        
        # æœªæ‰¾åˆ° - æä¾›å»ºè®®
        print(f"   âŒ NOT FOUND")
        
        # æŸ¥æ‰¾ç›¸ä¼¼çš„headers
        print(f"   ğŸ’¡ ç›¸ä¼¼çš„headers:")
        for level, title in all_headers:
            if required.lower().replace('#', '').strip() in title.lower():
                print(f"      - {level} {title}")
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    # é…ç½®
    work_dir = "demo_act"
    file_name = "market-research.md"
    file_path = f"{work_dir}/{file_name}"
    
    required_sections = [
        "## Executive Summary",
        "## Target Users",
        "## Competitor Analysis",
        "## Market Size",
        "## User Pain Points",
        "## Opportunities"
    ]
    
    diagnose_file(file_path, required_sections)

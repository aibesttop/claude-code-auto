# ç³»ç»Ÿå¢å¼ºæ–¹æ¡ˆ v4.1 - ç”Ÿäº§çº§å¥å£®æ€§å¢å¼º

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäºv4.0æ¶æ„é‡æ„ï¼Œæå‡º8ä¸ªå…³é”®ç»´åº¦çš„ç³»ç»Ÿå¢å¼ºæ–¹æ¡ˆï¼Œæ—¨åœ¨æå‡ç³»ç»Ÿçš„**å¥å£®æ€§ã€å¯è§‚æµ‹æ€§ã€å¯æ¢å¤æ€§å’Œèµ„æºç®¡ç†èƒ½åŠ›**ï¼Œä½¿å…¶è¾¾åˆ°ç”Ÿäº§çº§æ ‡å‡†ã€‚

---

## ğŸ¯ å¢å¼ºç»´åº¦æ€»è§ˆ

| ç»´åº¦ | æ ¸å¿ƒé—®é¢˜ | å¢å¼ºæ–¹æ¡ˆ | ä¼˜å…ˆçº§ |
|------|----------|----------|--------|
| **1. ç»“æ„åŒ–åè®®** | SubMission/Contextå®šä¹‰ä¸è§„èŒƒ | JSON Schema + ç‰ˆæœ¬åŒ– | P0 |
| **2. è¯„ä¼°å¼ºåŒ–** | è´¨é‡è¯„ä¼°ä¾èµ–å•ä¸€LLM | å¤šç»´åº¦è¯„ä¼° + å¯é‡æ”¾ | P0 |
| **3. æˆæœ¬ä¸èŠ‚æµ** | ç¼ºä¹ç»†ç²’åº¦é¢„ç®—æ§åˆ¶ | åŠ¨æ€é¢„ç®— + ç†”æ–­ | P0 |
| **4. å¹‚ç­‰ä¸æ¢å¤** | ä¸æ”¯æŒæ–­ç‚¹ç»­è·‘ | çŠ¶æ€æŒä¹…åŒ– + å¹‚ç­‰æ€§ | P1 |
| **5. èµ„æºéš”ç¦»** | å·¥å…·æƒé™ç¼ºä¹é™åˆ¶ | æœ€å°æƒé™ + é€Ÿç‡é™åˆ¶ | P1 |
| **6. è§‚æµ‹ä¸è¿½è¸ª** | ç¼ºä¹ç»“æ„åŒ–è¿½è¸ª | trace_id + ç»“æ„åŒ–æ—¥å¿— | P0 |
| **7. ç»ˆæ€ç­–ç•¥** | å¤±è´¥æ—¶ç¼ºä¹æ¢å¤æŒ‡å— | éƒ¨åˆ†äº¤ä»˜ + é£é™©æŠ¥å‘Š | P2 |
| **8. è¾…åŠ©è§’è‰²æ²»ç†** | AddHelperå¯èƒ½æ— é™æ‰©å¼  | é€€åœºæ¡ä»¶ + é€€é¿ç­–ç•¥ | P1 |

---

## 1ï¸âƒ£ ç»“æ„åŒ–åè®®å®šä¹‰

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- SubMissionå®šä¹‰æ¾æ•£ï¼Œç¼ºä¹å¼ºåˆ¶æ ¡éªŒ
- Contextä¼ é€’æ ¼å¼ä¸ç»Ÿä¸€ï¼Œå®¹æ˜“ä¿¡æ¯æ¼‚ç§»
- ç¼ºä¹ç‰ˆæœ¬åŒ–æœºåˆ¶ï¼Œéš¾ä»¥è¿½æº¯å˜æ›´

### è§£å†³æ–¹æ¡ˆ

#### 1.1 SubMission Schemaå®šä¹‰

```yaml
# schemas/sub_mission.schema.yaml
$schema: "http://json-schema.org/draft-07/schema#"
title: SubMission
description: Leaderåˆ†è§£çš„å­ä»»åŠ¡å®šä¹‰

type: object
required:
  - id
  - type
  - goal
  - success_criteria
  - priority
  - dependencies
  - version

properties:
  id:
    type: string
    pattern: "^mission-[0-9a-f]{8}$"
    description: "ä»»åŠ¡å”¯ä¸€æ ‡è¯† (å¦‚ mission-1a2b3c4d)"

  version:
    type: string
    pattern: "^v[0-9]+\\.[0-9]+$"
    description: "ä»»åŠ¡å®šä¹‰ç‰ˆæœ¬ (å¦‚ v1.0, v1.1 ç”¨äºENHANCE)"

  type:
    type: string
    enum: [research, documentation, development, testing, deployment]
    description: "ä»»åŠ¡ç±»å‹"

  goal:
    type: string
    minLength: 50
    maxLength: 1000
    description: "ä»»åŠ¡ç›®æ ‡æè¿°"

  success_criteria:
    type: array
    minItems: 1
    maxItems: 10
    items:
      type: object
      required: [criterion, weight, validation_type]
      properties:
        criterion:
          type: string
          description: "æˆåŠŸæ ‡å‡†æè¿°"
        weight:
          type: number
          minimum: 0.0
          maximum: 1.0
          description: "æƒé‡ (æ‰€æœ‰æ ‡å‡†æ€»å’Œ=1.0)"
        validation_type:
          type: string
          enum: [file_exists, content_check, test_pass, llm_quality, custom]
        validation_config:
          type: object
          description: "éªŒè¯é…ç½® (æ ¹æ®validation_typeä¸åŒ)"

  priority:
    type: integer
    minimum: 1
    maximum: 10
    description: "ä¼˜å…ˆçº§ (1=æœ€é«˜, 10=æœ€ä½)"

  dependencies:
    type: array
    items:
      type: string
      pattern: "^mission-[0-9a-f]{8}$"
    description: "ä¾èµ–çš„ä»»åŠ¡IDåˆ—è¡¨"

  resources:
    type: object
    properties:
      tools:
        type: array
        items:
          type: string
        description: "å…è®¸ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨"
      mcp_servers:
        type: array
        items:
          type: string
        description: "å…è®¸ä½¿ç”¨çš„MCPæœåŠ¡å™¨"
      max_tokens:
        type: integer
        minimum: 1000
        description: "æœ€å¤§tokené¢„ç®—"
      max_duration_minutes:
        type: integer
        minimum: 1
        description: "æœ€å¤§æ‰§è¡Œæ—¶é•¿"

  budget:
    type: object
    required: [max_cost_usd, max_retries]
    properties:
      max_cost_usd:
        type: number
        minimum: 0.01
        description: "æœ€å¤§æˆæœ¬é¢„ç®—"
      max_retries:
        type: integer
        minimum: 0
        maximum: 5
        description: "æœ€å¤§é‡è¯•æ¬¡æ•°"
      retry_backoff:
        type: string
        enum: [linear, exponential, fibonacci]
        default: exponential
        description: "é‡è¯•é€€é¿ç­–ç•¥"

  metadata:
    type: object
    properties:
      created_at:
        type: string
        format: date-time
      created_by:
        type: string
        enum: [leader, user, enhanced]
      parent_mission:
        type: string
        description: "çˆ¶ä»»åŠ¡ID (å¦‚æœæ˜¯ENHANCE/ESCALATEäº§ç”Ÿ)"
      tags:
        type: array
        items:
          type: string

additionalProperties: false
```

#### 1.2 Contextä¼ é€’åè®®

```yaml
# schemas/execution_context.schema.yaml
$schema: "http://json-schema.org/draft-07/schema#"
title: ExecutionContext
description: è§’è‰²é—´ä¼ é€’çš„ä¸Šä¸‹æ–‡å¿«ç…§

type: object
required:
  - context_id
  - version
  - source_mission
  - target_mission
  - snapshot_time
  - content_type
  - content

properties:
  context_id:
    type: string
    pattern: "^ctx-[0-9a-f]{8}$"

  version:
    type: string
    pattern: "^v[0-9]+\\.[0-9]+$"
    description: "ä¸Šä¸‹æ–‡ç‰ˆæœ¬ (æ¯æ¬¡ä¼ é€’é€’å¢)"

  source_mission:
    type: string
    description: "æ¥æºä»»åŠ¡ID"

  target_mission:
    type: string
    description: "ç›®æ ‡ä»»åŠ¡ID"

  snapshot_time:
    type: string
    format: date-time

  content_type:
    type: string
    enum: [full, summary, reference]
    description: "å†…å®¹ç±»å‹"

  content:
    oneOf:
      - type: object  # full
        properties:
          files:
            type: array
            items:
              type: object
              properties:
                path:
                  type: string
                content:
                  type: string
                hash:
                  type: string
                  description: "SHA256 hashç”¨äºéªŒè¯"

      - type: object  # summary
        properties:
          summary_text:
            type: string
            maxLength: 2000
          reference_path:
            type: string
            description: "å®Œæ•´å†…å®¹å­˜å‚¨è·¯å¾„"
          hash:
            type: string

      - type: object  # reference
        properties:
          reference_path:
            type: string
          hash:
            type: string

  metadata:
    type: object
    properties:
      total_files:
        type: integer
      total_size_bytes:
        type: integer
      compression:
        type: string
        enum: [none, gzip, zstd]
      encryption:
        type: boolean
```

#### 1.3 å®ç°å»ºè®®

```python
# src/core/schemas/validator.py
from jsonschema import validate, ValidationError
import yaml
from pathlib import Path

class SchemaValidator:
    """SchemaéªŒè¯å™¨"""

    def __init__(self):
        schema_dir = Path(__file__).parent / "schemas"

        # åŠ è½½æ‰€æœ‰schema
        self.schemas = {
            "sub_mission": self._load_schema(schema_dir / "sub_mission.schema.yaml"),
            "execution_context": self._load_schema(schema_dir / "execution_context.schema.yaml"),
            "quality_score": self._load_schema(schema_dir / "quality_score.schema.yaml"),
        }

    def _load_schema(self, path: Path) -> dict:
        with open(path) as f:
            return yaml.safe_load(f)

    def validate_sub_mission(self, mission: dict) -> tuple[bool, str]:
        """
        éªŒè¯SubMissionå®šä¹‰

        Returns:
            (is_valid, error_message)
        """
        try:
            validate(instance=mission, schema=self.schemas["sub_mission"])

            # é¢å¤–ä¸šåŠ¡æ ¡éªŒ
            if not self._validate_success_criteria_weights(mission):
                return False, "Success criteria weights must sum to 1.0"

            if not self._validate_dependencies_acyclic(mission):
                return False, "Circular dependency detected"

            return True, ""

        except ValidationError as e:
            return False, f"Schema validation failed: {e.message}"

    def _validate_success_criteria_weights(self, mission: dict) -> bool:
        """éªŒè¯æˆåŠŸæ ‡å‡†æƒé‡æ€»å’Œä¸º1.0"""
        total_weight = sum(
            criterion["weight"]
            for criterion in mission.get("success_criteria", [])
        )
        return abs(total_weight - 1.0) < 0.01  # å…è®¸æµ®ç‚¹è¯¯å·®

    def _validate_dependencies_acyclic(self, mission: dict) -> bool:
        """éªŒè¯ä¾èµ–å…³ç³»æ— ç¯ (ç®€åŒ–æ£€æŸ¥)"""
        # å®é™…å®ç°éœ€è¦å…¨å±€ä¾èµ–å›¾
        return mission["id"] not in mission.get("dependencies", [])
```

#### 1.4 ç‰ˆæœ¬åŒ–ä¸Šä¸‹æ–‡ä¼ é€’ç­–ç•¥

```python
# src/core/context/versioned_context.py
import hashlib
import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

@dataclass
class ContextSnapshot:
    """ç‰ˆæœ¬åŒ–ä¸Šä¸‹æ–‡å¿«ç…§"""
    context_id: str
    version: str
    source_mission: str
    target_mission: str
    snapshot_time: datetime
    content_type: str  # full, summary, reference
    content: dict
    hash: str  # ç”¨äºéªŒè¯å®Œæ•´æ€§

class VersionedContextManager:
    """ç‰ˆæœ¬åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, storage_dir: Path):
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        self.version_counter = 0

    def create_snapshot(
        self,
        source_mission: str,
        target_mission: str,
        content: dict,
        threshold_bytes: int = 50000  # 50KBé˜ˆå€¼
    ) -> ContextSnapshot:
        """
        åˆ›å»ºä¸Šä¸‹æ–‡å¿«ç…§

        ç­–ç•¥ï¼š
        - < 50KB: full (å®Œæ•´åµŒå…¥)
        - >= 50KB: summary + reference (æ‘˜è¦+å¼•ç”¨)
        """
        self.version_counter += 1
        version = f"v1.{self.version_counter}"
        context_id = f"ctx-{hashlib.md5(f'{source_mission}-{target_mission}-{version}'.encode()).hexdigest()[:8]}"

        # è®¡ç®—å†…å®¹å¤§å°
        content_json = json.dumps(content, ensure_ascii=False)
        content_bytes = len(content_json.encode('utf-8'))

        if content_bytes < threshold_bytes:
            # ç­–ç•¥1: å®Œæ•´åµŒå…¥
            snapshot = ContextSnapshot(
                context_id=context_id,
                version=version,
                source_mission=source_mission,
                target_mission=target_mission,
                snapshot_time=datetime.utcnow(),
                content_type="full",
                content=content,
                hash=hashlib.sha256(content_json.encode()).hexdigest()
            )
        else:
            # ç­–ç•¥2: æ‘˜è¦+å¼•ç”¨
            summary = self._generate_summary(content)
            reference_path = self._save_full_content(context_id, content)

            snapshot = ContextSnapshot(
                context_id=context_id,
                version=version,
                source_mission=source_mission,
                target_mission=target_mission,
                snapshot_time=datetime.utcnow(),
                content_type="summary",
                content={
                    "summary_text": summary,
                    "reference_path": str(reference_path),
                    "hash": hashlib.sha256(content_json.encode()).hexdigest()
                },
                hash=hashlib.sha256(content_json.encode()).hexdigest()
            )

        # æŒä¹…åŒ–å¿«ç…§å…ƒæ•°æ®
        self._save_snapshot_metadata(snapshot)

        return snapshot

    def _generate_summary(self, content: dict) -> str:
        """ç”Ÿæˆå†…å®¹æ‘˜è¦ (å‰300å­— + å100å­—)"""
        content_str = json.dumps(content, ensure_ascii=False, indent=2)
        if len(content_str) <= 400:
            return content_str
        return content_str[:300] + "\n...\n" + content_str[-100:]

    def _save_full_content(self, context_id: str, content: dict) -> Path:
        """ä¿å­˜å®Œæ•´å†…å®¹åˆ°æ–‡ä»¶"""
        path = self.storage_dir / f"{context_id}_full.json"
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(content, f, ensure_ascii=False, indent=2)
        return path

    def _save_snapshot_metadata(self, snapshot: ContextSnapshot):
        """ä¿å­˜å¿«ç…§å…ƒæ•°æ®"""
        metadata_path = self.storage_dir / f"{snapshot.context_id}_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump({
                "context_id": snapshot.context_id,
                "version": snapshot.version,
                "source_mission": snapshot.source_mission,
                "target_mission": snapshot.target_mission,
                "snapshot_time": snapshot.snapshot_time.isoformat(),
                "content_type": snapshot.content_type,
                "hash": snapshot.hash
            }, f, indent=2)

    def verify_integrity(self, snapshot: ContextSnapshot) -> bool:
        """éªŒè¯å¿«ç…§å®Œæ•´æ€§"""
        if snapshot.content_type == "full":
            current_hash = hashlib.sha256(
                json.dumps(snapshot.content, ensure_ascii=False).encode()
            ).hexdigest()
        else:
            # ä»å¼•ç”¨è·¯å¾„è¯»å–å®Œæ•´å†…å®¹éªŒè¯
            reference_path = Path(snapshot.content["reference_path"])
            with open(reference_path) as f:
                full_content = f.read()
            current_hash = hashlib.sha256(full_content.encode()).hexdigest()

        return current_hash == snapshot.hash
```

---

## 2ï¸âƒ£ è¯„ä¼°å¼ºåŒ–

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- è´¨é‡è¯„ä¼°ä»…ä¾èµ–å•ä¸€LLMè¯­ä¹‰è¯„åˆ†
- ç¼ºä¹å®¢è§‚åº¦é‡ï¼ˆæµ‹è¯•è¦†ç›–ç‡ã€é™æ€æ£€æŸ¥ï¼‰
- åˆ¤åˆ†ç†ç”±ä¸å¯è¿½æº¯ï¼Œéš¾ä»¥é‡æ”¾éªŒè¯

### è§£å†³æ–¹æ¡ˆ

#### 2.1 å¤šç»´åº¦è¯„ä¼°æ¡†æ¶

```python
# src/core/quality/multi_dim_evaluator.py
from dataclasses import dataclass
from typing import List, Dict, Any
from enum import Enum

class EvaluationDimension(Enum):
    """è¯„ä¼°ç»´åº¦"""
    FORMAT = "format"              # æ ¼å¼éªŒè¯
    CONTENT = "content"            # å†…å®¹å®Œæ•´æ€§
    QUALITY_LLM = "quality_llm"    # LLMè¯­ä¹‰è´¨é‡
    TESTS = "tests"                # è‡ªåŠ¨åŒ–æµ‹è¯•
    STATIC_CHECKS = "static"       # é™æ€æ£€æŸ¥ (lint, type)
    SECURITY = "security"          # å®‰å…¨æ£€æŸ¥
    PERFORMANCE = "performance"    # æ€§èƒ½æŒ‡æ ‡

@dataclass
class DimensionScore:
    """å•ä¸ªç»´åº¦çš„è¯„åˆ†"""
    dimension: EvaluationDimension
    score: float  # 0-100
    weight: float  # æƒé‡
    evidence: Dict[str, Any]  # è¯„åˆ†è¯æ®
    issues: List[str]  # å‘ç°çš„é—®é¢˜
    suggestions: List[str]  # æ”¹è¿›å»ºè®®

@dataclass
class MultiDimEvaluation:
    """å¤šç»´åº¦è¯„ä¼°ç»“æœ"""
    overall_score: float  # åŠ æƒæ€»åˆ†
    dimension_scores: List[DimensionScore]
    passed: bool  # æ˜¯å¦é€šè¿‡é˜ˆå€¼
    threshold: float
    evaluation_time: str
    evaluator_version: str
    replay_context: Dict[str, Any]  # ç”¨äºé‡æ”¾çš„ä¸Šä¸‹æ–‡

class MultiDimEvaluator:
    """å¤šç»´åº¦è¯„ä¼°å™¨"""

    def __init__(
        self,
        enable_tests: bool = True,
        enable_static: bool = True,
        enable_security: bool = False,
        llm_model: str = "haiku"
    ):
        self.enable_tests = enable_tests
        self.enable_static = enable_static
        self.enable_security = enable_security
        self.llm_model = llm_model

        # ç»´åº¦æƒé‡é…ç½®
        self.dimension_weights = {
            EvaluationDimension.FORMAT: 0.15,
            EvaluationDimension.CONTENT: 0.20,
            EvaluationDimension.QUALITY_LLM: 0.30,
            EvaluationDimension.TESTS: 0.20,
            EvaluationDimension.STATIC_CHECKS: 0.10,
            EvaluationDimension.SECURITY: 0.05,
        }

    async def evaluate(
        self,
        mission: dict,
        outputs: List[str],
        work_dir: Path
    ) -> MultiDimEvaluation:
        """
        æ‰§è¡Œå¤šç»´åº¦è¯„ä¼°

        Args:
            mission: SubMissionå®šä¹‰
            outputs: è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
            work_dir: å·¥ä½œç›®å½•

        Returns:
            MultiDimEvaluationç»“æœ
        """
        dimension_scores = []

        # 1. æ ¼å¼éªŒè¯
        format_score = await self._evaluate_format(mission, outputs, work_dir)
        dimension_scores.append(format_score)

        # 2. å†…å®¹å®Œæ•´æ€§
        content_score = await self._evaluate_content(mission, outputs, work_dir)
        dimension_scores.append(content_score)

        # 3. LLMè¯­ä¹‰è´¨é‡
        llm_score = await self._evaluate_llm_quality(mission, outputs, work_dir)
        dimension_scores.append(llm_score)

        # 4. è‡ªåŠ¨åŒ–æµ‹è¯• (å¯é€‰)
        if self.enable_tests:
            test_score = await self._evaluate_tests(mission, work_dir)
            dimension_scores.append(test_score)

        # 5. é™æ€æ£€æŸ¥ (å¯é€‰)
        if self.enable_static:
            static_score = await self._evaluate_static_checks(mission, work_dir)
            dimension_scores.append(static_score)

        # 6. å®‰å…¨æ£€æŸ¥ (å¯é€‰)
        if self.enable_security:
            security_score = await self._evaluate_security(mission, outputs, work_dir)
            dimension_scores.append(security_score)

        # è®¡ç®—åŠ æƒæ€»åˆ†
        overall_score = sum(
            ds.score * self.dimension_weights.get(ds.dimension, 0.0)
            for ds in dimension_scores
        )

        # ç”Ÿæˆé‡æ”¾ä¸Šä¸‹æ–‡
        replay_context = {
            "mission_id": mission["id"],
            "mission_version": mission["version"],
            "outputs": outputs,
            "work_dir": str(work_dir),
            "evaluator_config": {
                "enable_tests": self.enable_tests,
                "enable_static": self.enable_static,
                "enable_security": self.enable_security,
                "llm_model": self.llm_model,
            },
            "dimension_weights": {
                k.value: v for k, v in self.dimension_weights.items()
            }
        }

        threshold = mission.get("quality_threshold", 70.0)

        return MultiDimEvaluation(
            overall_score=overall_score,
            dimension_scores=dimension_scores,
            passed=overall_score >= threshold,
            threshold=threshold,
            evaluation_time=datetime.utcnow().isoformat(),
            evaluator_version="v1.0",
            replay_context=replay_context
        )

    async def _evaluate_tests(
        self,
        mission: dict,
        work_dir: Path
    ) -> DimensionScore:
        """
        è¯„ä¼°ç»´åº¦: è‡ªåŠ¨åŒ–æµ‹è¯•

        è¿è¡Œpytestå¹¶åˆ†æè¦†ç›–ç‡
        """
        import subprocess

        issues = []
        suggestions = []
        evidence = {}

        try:
            # è¿è¡Œpytest with coverage
            result = subprocess.run(
                ["pytest", "--cov=.", "--cov-report=json", "tests/"],
                cwd=work_dir,
                capture_output=True,
                text=True,
                timeout=300
            )

            # è§£æè¦†ç›–ç‡æŠ¥å‘Š
            coverage_path = work_dir / "coverage.json"
            if coverage_path.exists():
                import json
                with open(coverage_path) as f:
                    coverage_data = json.load(f)
                    coverage_percent = coverage_data["totals"]["percent_covered"]
                    evidence["coverage_percent"] = coverage_percent
            else:
                coverage_percent = 0.0

            # è§£ææµ‹è¯•ç»“æœ
            if "passed" in result.stdout:
                # æå–é€šè¿‡/å¤±è´¥æ•°é‡
                import re
                match = re.search(r'(\d+) passed', result.stdout)
                passed = int(match.group(1)) if match else 0
                match = re.search(r'(\d+) failed', result.stdout)
                failed = int(match.group(1)) if match else 0

                evidence["tests_passed"] = passed
                evidence["tests_failed"] = failed

                if failed > 0:
                    issues.append(f"{failed} tests failed")
                    suggestions.append("Fix failing tests before proceeding")

            # è¯„åˆ†é€»è¾‘
            # åŸºç¡€åˆ†: æµ‹è¯•é€šè¿‡ç‡ * 50
            # è¦†ç›–ç‡åŠ åˆ†: (coverage / 80) * 50
            test_pass_rate = passed / (passed + failed) if (passed + failed) > 0 else 0
            score = (test_pass_rate * 50) + (min(coverage_percent / 80, 1.0) * 50)

            if coverage_percent < 70:
                issues.append(f"Test coverage is {coverage_percent:.1f}% (target: 70%+)")
                suggestions.append("Increase test coverage")

        except subprocess.TimeoutExpired:
            score = 0.0
            issues.append("Test execution timeout (>5min)")
            suggestions.append("Optimize test execution time")
        except Exception as e:
            score = 0.0
            issues.append(f"Test execution failed: {e}")

        return DimensionScore(
            dimension=EvaluationDimension.TESTS,
            score=score,
            weight=self.dimension_weights[EvaluationDimension.TESTS],
            evidence=evidence,
            issues=issues,
            suggestions=suggestions
        )

    async def _evaluate_static_checks(
        self,
        mission: dict,
        work_dir: Path
    ) -> DimensionScore:
        """
        è¯„ä¼°ç»´åº¦: é™æ€æ£€æŸ¥

        è¿è¡Œ flake8 (linting) + mypy (type checking)
        """
        import subprocess

        issues = []
        suggestions = []
        evidence = {}

        # 1. Flake8 linting
        try:
            result = subprocess.run(
                ["flake8", ".", "--count", "--select=E9,F63,F7,F82", "--show-source"],
                cwd=work_dir,
                capture_output=True,
                text=True,
                timeout=60
            )

            lint_errors = result.stdout.count('\n')
            evidence["lint_errors"] = lint_errors

            if lint_errors > 0:
                issues.append(f"{lint_errors} linting errors")
                suggestions.append("Run 'flake8 .' to see detailed errors")

        except Exception as e:
            evidence["lint_errors"] = -1  # æœªæ‰§è¡Œ

        # 2. Mypy type checking
        try:
            result = subprocess.run(
                ["mypy", ".", "--strict"],
                cwd=work_dir,
                capture_output=True,
                text=True,
                timeout=60
            )

            type_errors = result.stdout.count('error:')
            evidence["type_errors"] = type_errors

            if type_errors > 0:
                issues.append(f"{type_errors} type errors")
                suggestions.append("Add type hints and fix type errors")

        except Exception as e:
            evidence["type_errors"] = -1

        # è¯„åˆ†é€»è¾‘
        lint_score = max(0, 100 - lint_errors * 5)  # æ¯ä¸ªé”™è¯¯æ‰£5åˆ†
        type_score = max(0, 100 - type_errors * 2)  # æ¯ä¸ªé”™è¯¯æ‰£2åˆ†
        score = (lint_score * 0.6 + type_score * 0.4)

        return DimensionScore(
            dimension=EvaluationDimension.STATIC_CHECKS,
            score=score,
            weight=self.dimension_weights[EvaluationDimension.STATIC_CHECKS],
            evidence=evidence,
            issues=issues,
            suggestions=suggestions
        )
```

#### 2.2 è¯„ä¼°ç»“æœå¯é‡æ”¾

```python
# src/core/quality/evaluation_replay.py
import json
from pathlib import Path
from datetime import datetime

class EvaluationReplay:
    """è¯„ä¼°ç»“æœé‡æ”¾å™¨"""

    def __init__(self, replay_dir: Path):
        self.replay_dir = replay_dir
        self.replay_dir.mkdir(parents=True, exist_ok=True)

    def save_evaluation(
        self,
        evaluation: MultiDimEvaluation,
        mission_id: str
    ):
        """
        ä¿å­˜è¯„ä¼°ç»“æœç”¨äºé‡æ”¾

        æ ¼å¼: logs/evaluations/{mission_id}_{timestamp}.json
        """
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        filename = f"{mission_id}_{timestamp}.json"

        eval_data = {
            "mission_id": mission_id,
            "timestamp": timestamp,
            "overall_score": evaluation.overall_score,
            "passed": evaluation.passed,
            "threshold": evaluation.threshold,
            "evaluator_version": evaluation.evaluator_version,
            "dimension_scores": [
                {
                    "dimension": ds.dimension.value,
                    "score": ds.score,
                    "weight": ds.weight,
                    "evidence": ds.evidence,
                    "issues": ds.issues,
                    "suggestions": ds.suggestions
                }
                for ds in evaluation.dimension_scores
            ],
            "replay_context": evaluation.replay_context
        }

        path = self.replay_dir / filename
        with open(path, 'w') as f:
            json.dump(eval_data, f, indent=2, ensure_ascii=False)

        return path

    def load_evaluation(self, path: Path) -> dict:
        """åŠ è½½å†å²è¯„ä¼°ç»“æœ"""
        with open(path) as f:
            return json.load(f)

    async def replay_evaluation(
        self,
        eval_data: dict,
        evaluator: MultiDimEvaluator
    ) -> MultiDimEvaluation:
        """
        é‡æ”¾è¯„ä¼° (é‡æ–°æ‰§è¡Œ)

        ä½¿ç”¨ç›¸åŒçš„é…ç½®å’Œè¾“å…¥é‡æ–°è¯„ä¼°
        """
        replay_ctx = eval_data["replay_context"]

        # æ¢å¤è¯„ä¼°å™¨é…ç½®
        evaluator.enable_tests = replay_ctx["evaluator_config"]["enable_tests"]
        evaluator.enable_static = replay_ctx["evaluator_config"]["enable_static"]
        evaluator.enable_security = replay_ctx["evaluator_config"]["enable_security"]

        # é‡æ–°æ‰§è¡Œè¯„ä¼°
        mission = {
            "id": replay_ctx["mission_id"],
            "version": replay_ctx["mission_version"]
        }

        result = await evaluator.evaluate(
            mission=mission,
            outputs=replay_ctx["outputs"],
            work_dir=Path(replay_ctx["work_dir"])
        )

        return result

    def compare_evaluations(
        self,
        eval1: dict,
        eval2: dict
    ) -> dict:
        """
        å¯¹æ¯”ä¸¤æ¬¡è¯„ä¼°ç»“æœ

        ç”¨äºéªŒè¯è¯„ä¼°çš„ä¸€è‡´æ€§æˆ–åˆ†ææ”¹è¿›
        """
        comparison = {
            "score_diff": eval2["overall_score"] - eval1["overall_score"],
            "dimension_diffs": [],
            "issues_resolved": [],
            "issues_new": []
        }

        # å¯¹æ¯”å„ç»´åº¦åˆ†æ•°
        dims1 = {d["dimension"]: d for d in eval1["dimension_scores"]}
        dims2 = {d["dimension"]: d for d in eval2["dimension_scores"]}

        for dim_name in dims1:
            if dim_name in dims2:
                diff = dims2[dim_name]["score"] - dims1[dim_name]["score"]
                comparison["dimension_diffs"].append({
                    "dimension": dim_name,
                    "diff": diff,
                    "before": dims1[dim_name]["score"],
                    "after": dims2[dim_name]["score"]
                })

        # å¯¹æ¯”issues
        issues1_set = set(sum([d["issues"] for d in eval1["dimension_scores"]], []))
        issues2_set = set(sum([d["issues"] for d in eval2["dimension_scores"]], []))

        comparison["issues_resolved"] = list(issues1_set - issues2_set)
        comparison["issues_new"] = list(issues2_set - issues1_set)

        return comparison
```

---

## 3ï¸âƒ£ æˆæœ¬ä¸èŠ‚æµæ§åˆ¶

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- ä»…æœ‰å…¨å±€é¢„ç®—é™åˆ¶ï¼Œç¼ºä¹ä»»åŠ¡çº§/è§’è‰²çº§é¢„ç®—
- Retry/Enhance/AddHelperæ²¡æœ‰æˆæœ¬é™åˆ¶
- ç¼ºä¹åŠ¨æ€é¢„ç®—åˆ†é…å’Œä¼˜å…ˆçº§é™çº§æœºåˆ¶

### è§£å†³æ–¹æ¡ˆ

#### 3.1 åˆ†å±‚é¢„ç®—æ§åˆ¶

```python
# src/core/budget/hierarchical_budget.py
from dataclasses import dataclass
from typing import Dict, Optional
from enum import Enum

class BudgetLevel(Enum):
    """é¢„ç®—å±‚çº§"""
    SESSION = "session"      # ä¼šè¯çº§
    MISSION = "mission"      # ä»»åŠ¡çº§
    ROLE = "role"           # è§’è‰²çº§
    ACTION = "action"       # åŠ¨ä½œçº§ (Retry/Enhance/Escalate)

@dataclass
class BudgetAllocation:
    """é¢„ç®—åˆ†é…"""
    level: BudgetLevel
    entity_id: str
    max_cost_usd: float
    max_tokens: int
    max_duration_minutes: int
    priority: int  # 1-10, ç”¨äºé™çº§å†³ç­–

    # å½“å‰ä½¿ç”¨æƒ…å†µ
    used_cost_usd: float = 0.0
    used_tokens: int = 0
    used_duration_minutes: float = 0.0

    # ç†”æ–­é˜ˆå€¼
    warning_threshold: float = 0.8  # 80%è­¦å‘Š
    critical_threshold: float = 0.95  # 95%ç†”æ–­

class HierarchicalBudgetController:
    """åˆ†å±‚é¢„ç®—æ§åˆ¶å™¨"""

    def __init__(
        self,
        session_budget_usd: float,
        default_mission_budget_ratio: float = 0.3,
        default_role_budget_ratio: float = 0.15
    ):
        self.session_budget = BudgetAllocation(
            level=BudgetLevel.SESSION,
            entity_id="session",
            max_cost_usd=session_budget_usd,
            max_tokens=1000000,  # 1M tokens
            max_duration_minutes=480,  # 8 hours
            priority=1
        )

        self.default_mission_budget_ratio = default_mission_budget_ratio
        self.default_role_budget_ratio = default_role_budget_ratio

        # é¢„ç®—åˆ†é…è¡¨
        self.allocations: Dict[str, BudgetAllocation] = {
            "session": self.session_budget
        }

    def allocate_mission_budget(
        self,
        mission_id: str,
        priority: int,
        custom_ratio: Optional[float] = None
    ) -> BudgetAllocation:
        """
        ä¸ºä»»åŠ¡åˆ†é…é¢„ç®—

        ç­–ç•¥:
        - é«˜ä¼˜å…ˆçº§ä»»åŠ¡ (1-3): 30% sessioné¢„ç®—
        - ä¸­ä¼˜å…ˆçº§ä»»åŠ¡ (4-7): 20% sessioné¢„ç®—
        - ä½ä¼˜å…ˆçº§ä»»åŠ¡ (8-10): 10% sessioné¢„ç®—
        """
        if custom_ratio:
            ratio = custom_ratio
        else:
            if priority <= 3:
                ratio = 0.30
            elif priority <= 7:
                ratio = 0.20
            else:
                ratio = 0.10

        mission_budget = BudgetAllocation(
            level=BudgetLevel.MISSION,
            entity_id=mission_id,
            max_cost_usd=self.session_budget.max_cost_usd * ratio,
            max_tokens=int(self.session_budget.max_tokens * ratio),
            max_duration_minutes=int(self.session_budget.max_duration_minutes * ratio),
            priority=priority
        )

        self.allocations[mission_id] = mission_budget
        return mission_budget

    def allocate_role_budget(
        self,
        mission_id: str,
        role_id: str,
        custom_ratio: Optional[float] = None
    ) -> BudgetAllocation:
        """ä¸ºè§’è‰²åˆ†é…é¢„ç®— (ä»ä»»åŠ¡é¢„ç®—ä¸­åˆ†é…)"""
        mission_budget = self.allocations.get(mission_id)
        if not mission_budget:
            raise ValueError(f"Mission {mission_id} budget not found")

        ratio = custom_ratio or self.default_role_budget_ratio

        role_budget = BudgetAllocation(
            level=BudgetLevel.ROLE,
            entity_id=role_id,
            max_cost_usd=mission_budget.max_cost_usd * ratio,
            max_tokens=int(mission_budget.max_tokens * ratio),
            max_duration_minutes=int(mission_budget.max_duration_minutes * ratio),
            priority=mission_budget.priority
        )

        self.allocations[role_id] = role_budget
        return role_budget

    def allocate_action_budget(
        self,
        role_id: str,
        action_type: str,  # "retry", "enhance", "escalate"
        attempt_number: int
    ) -> BudgetAllocation:
        """
        ä¸ºå¹²é¢„åŠ¨ä½œåˆ†é…é¢„ç®—

        ç­–ç•¥:
        - Retry: é€æ¬¡é€’å‡ (50% -> 30% -> 10%)
        - Enhance: å›ºå®š20%
        - Escalate: å›ºå®š50% (æ·»åŠ è¾…åŠ©è§’è‰²)
        """
        role_budget = self.allocations.get(role_id)
        if not role_budget:
            raise ValueError(f"Role {role_id} budget not found")

        if action_type == "retry":
            ratios = [0.5, 0.3, 0.1, 0.05]
            ratio = ratios[min(attempt_number - 1, len(ratios) - 1)]
        elif action_type == "enhance":
            ratio = 0.2
        elif action_type == "escalate":
            ratio = 0.5
        else:
            ratio = 0.1

        action_id = f"{role_id}_{action_type}_{attempt_number}"

        action_budget = BudgetAllocation(
            level=BudgetLevel.ACTION,
            entity_id=action_id,
            max_cost_usd=role_budget.max_cost_usd * ratio,
            max_tokens=int(role_budget.max_tokens * ratio),
            max_duration_minutes=int(role_budget.max_duration_minutes * ratio),
            priority=role_budget.priority
        )

        self.allocations[action_id] = action_budget
        return action_budget

    def check_budget(
        self,
        entity_id: str,
        cost_delta: float = 0.0,
        tokens_delta: int = 0
    ) -> tuple[str, float]:
        """
        æ£€æŸ¥é¢„ç®—çŠ¶æ€

        Returns:
            (status, usage_ratio)
            status: "ok", "warning", "critical", "exceeded"
        """
        budget = self.allocations.get(entity_id)
        if not budget:
            return "ok", 0.0

        # è®¡ç®—ä½¿ç”¨ç‡
        cost_usage = (budget.used_cost_usd + cost_delta) / budget.max_cost_usd
        token_usage = (budget.used_tokens + tokens_delta) / budget.max_tokens

        max_usage = max(cost_usage, token_usage)

        if max_usage >= 1.0:
            return "exceeded", max_usage
        elif max_usage >= budget.critical_threshold:
            return "critical", max_usage
        elif max_usage >= budget.warning_threshold:
            return "warning", max_usage
        else:
            return "ok", max_usage

    def record_usage(
        self,
        entity_id: str,
        cost_usd: float,
        tokens: int,
        duration_minutes: float
    ):
        """è®°å½•èµ„æºä½¿ç”¨"""
        budget = self.allocations.get(entity_id)
        if not budget:
            return

        budget.used_cost_usd += cost_usd
        budget.used_tokens += tokens
        budget.used_duration_minutes += duration_minutes

        # åŒæ—¶æ›´æ–°çˆ¶çº§é¢„ç®—
        if budget.level == BudgetLevel.ACTION:
            # Action -> Role -> Mission -> Session
            role_id = "_".join(entity_id.split("_")[:-2])
            self.record_usage(role_id, cost_usd, tokens, duration_minutes)

        elif budget.level == BudgetLevel.ROLE:
            # Role -> Mission -> Session
            mission_id = budget.entity_id.split("_role_")[0]  # å‡è®¾role_idæ ¼å¼: mission-xxx_role_yyy
            self.record_usage(mission_id, cost_usd, tokens, duration_minutes)

        elif budget.level == BudgetLevel.MISSION:
            # Mission -> Session
            self.record_usage("session", cost_usd, tokens, duration_minutes)

    def get_priority_sorted_missions(self) -> List[str]:
        """
        è·å–æŒ‰ä¼˜å…ˆçº§æ’åºçš„ä»»åŠ¡åˆ—è¡¨

        ç”¨äºé¢„ç®—ç´§å¼ æ—¶çš„é™çº§å†³ç­–
        """
        mission_budgets = [
            (entity_id, budget)
            for entity_id, budget in self.allocations.items()
            if budget.level == BudgetLevel.MISSION
        ]

        # æŒ‰ä¼˜å…ˆçº§æ’åº (ä½ä¼˜å…ˆçº§åœ¨å‰ï¼Œç”¨äºé™çº§)
        sorted_missions = sorted(
            mission_budgets,
            key=lambda x: x[1].priority,
            reverse=True
        )

        return [entity_id for entity_id, _ in sorted_missions]
```

#### 3.2 åŠ¨æ€é¢„ç®—è°ƒæ•´å’Œç†”æ–­

```python
# src/core/budget/circuit_breaker.py
from enum import Enum
from dataclasses import dataclass
from datetime import datetime, timedelta

class CircuitState(Enum):
    """ç†”æ–­å™¨çŠ¶æ€"""
    CLOSED = "closed"       # æ­£å¸¸è¿è¡Œ
    OPEN = "open"           # ç†”æ–­å¼€å¯
    HALF_OPEN = "half_open" # åŠå¼€ (å°è¯•æ¢å¤)

@dataclass
class CircuitBreakerConfig:
    """ç†”æ–­å™¨é…ç½®"""
    failure_threshold: int = 3  # å¤±è´¥é˜ˆå€¼
    success_threshold: int = 2  # æ¢å¤é˜ˆå€¼
    timeout_seconds: int = 300  # ç†”æ–­è¶…æ—¶ (5åˆ†é’Ÿåå°è¯•æ¢å¤)

class BudgetCircuitBreaker:
    """é¢„ç®—ç†”æ–­å™¨"""

    def __init__(self, config: CircuitBreakerConfig):
        self.config = config
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time: Optional[datetime] = None

    def on_budget_exceeded(self, entity_id: str, usage_ratio: float):
        """é¢„ç®—è¶…é™äº‹ä»¶"""
        self.failure_count += 1
        self.last_failure_time = datetime.utcnow()

        if self.failure_count >= self.config.failure_threshold:
            self.state = CircuitState.OPEN
            logger.critical(
                f"Circuit breaker OPEN for {entity_id} "
                f"(failures: {self.failure_count}, usage: {usage_ratio:.1%})"
            )

    def on_budget_ok(self):
        """é¢„ç®—æ­£å¸¸äº‹ä»¶"""
        if self.state == CircuitState.HALF_OPEN:
            self.success_count += 1

            if self.success_count >= self.config.success_threshold:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                self.success_count = 0
                logger.info("Circuit breaker CLOSED (recovered)")

    def should_allow_execution(self) -> bool:
        """æ˜¯å¦å…è®¸æ‰§è¡Œ"""
        if self.state == CircuitState.CLOSED:
            return True

        elif self.state == CircuitState.OPEN:
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥å°è¯•æ¢å¤
            if self.last_failure_time:
                elapsed = (datetime.utcnow() - self.last_failure_time).total_seconds()
                if elapsed >= self.config.timeout_seconds:
                    self.state = CircuitState.HALF_OPEN
                    self.success_count = 0
                    logger.info("Circuit breaker HALF_OPEN (attempting recovery)")
                    return True
            return False

        elif self.state == CircuitState.HALF_OPEN:
            # åŠå¼€çŠ¶æ€å…è®¸å°‘é‡è¯·æ±‚é€šè¿‡
            return True

        return False
```

---

## 4ï¸âƒ£ å¹‚ç­‰ä¸æ¢å¤æœºåˆ¶

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- æ‰§è¡Œå™¨ä¸æ”¯æŒå¹‚ç­‰æ€§ï¼Œé‡å¤æ‰§è¡Œä¼šäº§ç”Ÿé‡å¤æ–‡ä»¶
- æ²¡æœ‰æ‰§è¡ŒçŠ¶æ€æŒä¹…åŒ–ï¼Œæ— æ³•æ–­ç‚¹ç»­è·‘
- ç³»ç»Ÿå´©æºƒåéœ€è¦ä»å¤´å¼€å§‹

### è§£å†³æ–¹æ¡ˆ

#### 4.1 å¹‚ç­‰æ‰§è¡Œå™¨è®¾è®¡

```python
# src/core/execution/idempotent_executor.py
import hashlib
import json
from pathlib import Path
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

@dataclass
class ExecutionCheckpoint:
    """æ‰§è¡Œæ£€æŸ¥ç‚¹"""
    mission_id: str
    role_id: str
    iteration: int
    state: str  # "pending", "running", "completed", "failed"
    outputs: List[str]
    context_snapshot_id: str
    timestamp: datetime
    hash: str  # ç”¨äºéªŒè¯å¹‚ç­‰æ€§

class IdempotentExecutor:
    """å¹‚ç­‰æ‰§è¡Œå™¨"""

    def __init__(self, checkpoint_dir: Path):
        self.checkpoint_dir = checkpoint_dir
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

    def compute_execution_hash(
        self,
        mission: dict,
        context: dict
    ) -> str:
        """
        è®¡ç®—æ‰§è¡Œå“ˆå¸Œ

        åŸºäºä»»åŠ¡å®šä¹‰å’Œè¾“å…¥ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º
        """
        hash_input = json.dumps({
            "mission_id": mission["id"],
            "mission_version": mission["version"],
            "mission_goal": mission["goal"],
            "context_hash": hashlib.sha256(
                json.dumps(context, sort_keys=True).encode()
            ).hexdigest()
        }, sort_keys=True)

        return hashlib.sha256(hash_input.encode()).hexdigest()

    def load_checkpoint(
        self,
        mission_id: str,
        role_id: str
    ) -> Optional[ExecutionCheckpoint]:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint_path = self.checkpoint_dir / f"{mission_id}_{role_id}.json"

        if not checkpoint_path.exists():
            return None

        with open(checkpoint_path) as f:
            data = json.load(f)

        return ExecutionCheckpoint(
            mission_id=data["mission_id"],
            role_id=data["role_id"],
            iteration=data["iteration"],
            state=data["state"],
            outputs=data["outputs"],
            context_snapshot_id=data["context_snapshot_id"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            hash=data["hash"]
        )

    def save_checkpoint(self, checkpoint: ExecutionCheckpoint):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_path = self.checkpoint_dir / f"{checkpoint.mission_id}_{checkpoint.role_id}.json"

        with open(checkpoint_path, 'w') as f:
            json.dump({
                "mission_id": checkpoint.mission_id,
                "role_id": checkpoint.role_id,
                "iteration": checkpoint.iteration,
                "state": checkpoint.state,
                "outputs": checkpoint.outputs,
                "context_snapshot_id": checkpoint.context_snapshot_id,
                "timestamp": checkpoint.timestamp.isoformat(),
                "hash": checkpoint.hash
            }, f, indent=2)

    async def execute_idempotent(
        self,
        mission: dict,
        role: dict,
        context: dict,
        executor_func: Callable
    ) -> dict:
        """
        å¹‚ç­‰æ‰§è¡Œ

        æµç¨‹:
        1. è®¡ç®—æ‰§è¡Œå“ˆå¸Œ
        2. æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒå“ˆå¸Œçš„å®Œæˆæ£€æŸ¥ç‚¹
        3. å¦‚æœæœ‰ï¼Œç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
        4. å¦‚æœæ²¡æœ‰ï¼Œæ‰§è¡Œå¹¶ä¿å­˜æ£€æŸ¥ç‚¹
        """
        mission_id = mission["id"]
        role_id = role["name"]
        execution_hash = self.compute_execution_hash(mission, context)

        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = self.load_checkpoint(mission_id, role_id)

        # æ£€æŸ¥å¹‚ç­‰æ€§
        if checkpoint and checkpoint.hash == execution_hash:
            if checkpoint.state == "completed":
                logger.info(
                    f"Idempotent cache hit for {role_id} "
                    f"(hash: {execution_hash[:8]})"
                )
                return {
                    "success": True,
                    "outputs": checkpoint.outputs,
                    "from_cache": True
                }
            elif checkpoint.state == "running":
                logger.warning(
                    f"Detected interrupted execution for {role_id}, resuming..."
                )
                # å¯ä»¥å°è¯•ä»ä¸­æ–­ç‚¹æ¢å¤

        # åˆ›å»ºæ–°æ£€æŸ¥ç‚¹ (runningçŠ¶æ€)
        checkpoint = ExecutionCheckpoint(
            mission_id=mission_id,
            role_id=role_id,
            iteration=0,
            state="running",
            outputs=[],
            context_snapshot_id=context.get("context_id", ""),
            timestamp=datetime.utcnow(),
            hash=execution_hash
        )
        self.save_checkpoint(checkpoint)

        try:
            # æ‰§è¡Œ
            result = await executor_func(mission, role, context)

            # æ›´æ–°æ£€æŸ¥ç‚¹ (completedçŠ¶æ€)
            checkpoint.state = "completed"
            checkpoint.outputs = result.get("outputs", [])
            checkpoint.timestamp = datetime.utcnow()
            self.save_checkpoint(checkpoint)

            return result

        except Exception as e:
            # æ›´æ–°æ£€æŸ¥ç‚¹ (failedçŠ¶æ€)
            checkpoint.state = "failed"
            checkpoint.timestamp = datetime.utcnow()
            self.save_checkpoint(checkpoint)

            raise e
```

#### 4.2 æ‰§è¡ŒçŠ¶æ€æŒä¹…åŒ–

```python
# src/core/execution/execution_state.py
from dataclasses import dataclass, asdict
from typing import List, Dict, Any
import json
from pathlib import Path

@dataclass
class MissionState:
    """ä»»åŠ¡çŠ¶æ€"""
    mission_id: str
    status: str  # "pending", "running", "completed", "failed", "paused"
    assigned_role: str
    progress: float  # 0.0 - 1.0
    current_iteration: int
    max_iterations: int
    outputs: List[str]
    last_checkpoint: str  # ISO timestamp

@dataclass
class TeamExecutionState:
    """å›¢é˜Ÿæ‰§è¡ŒçŠ¶æ€"""
    session_id: str
    execution_order: List[str]  # ä»»åŠ¡æ‰§è¡Œé¡ºåº
    completed_missions: List[str]
    current_mission_index: int
    mission_states: Dict[str, MissionState]
    total_cost_usd: float
    start_time: str
    last_update_time: str

class ExecutionStateManager:
    """æ‰§è¡ŒçŠ¶æ€ç®¡ç†å™¨"""

    def __init__(self, state_file: Path):
        self.state_file = state_file

    def save_state(self, state: TeamExecutionState):
        """ä¿å­˜æ‰§è¡ŒçŠ¶æ€"""
        self.state_file.parent.mkdir(parents=True, exist_ok=True)

        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        state_dict = {
            "session_id": state.session_id,
            "execution_order": state.execution_order,
            "completed_missions": state.completed_missions,
            "current_mission_index": state.current_mission_index,
            "mission_states": {
                mid: asdict(ms) for mid, ms in state.mission_states.items()
            },
            "total_cost_usd": state.total_cost_usd,
            "start_time": state.start_time,
            "last_update_time": datetime.utcnow().isoformat()
        }

        # åŸå­å†™å…¥ (ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶)
        temp_file = self.state_file.with_suffix('.tmp')
        with open(temp_file, 'w') as f:
            json.dump(state_dict, f, indent=2)

        temp_file.replace(self.state_file)

    def load_state(self) -> Optional[TeamExecutionState]:
        """åŠ è½½æ‰§è¡ŒçŠ¶æ€"""
        if not self.state_file.exists():
            return None

        with open(self.state_file) as f:
            state_dict = json.load(f)

        return TeamExecutionState(
            session_id=state_dict["session_id"],
            execution_order=state_dict["execution_order"],
            completed_missions=state_dict["completed_missions"],
            current_mission_index=state_dict["current_mission_index"],
            mission_states={
                mid: MissionState(**ms)
                for mid, ms in state_dict["mission_states"].items()
            },
            total_cost_usd=state_dict["total_cost_usd"],
            start_time=state_dict["start_time"],
            last_update_time=state_dict["last_update_time"]
        )

    def resume_execution(self) -> Optional[TeamExecutionState]:
        """
        æ¢å¤æ‰§è¡Œ

        Returns:
            å¦‚æœå­˜åœ¨å¯æ¢å¤çš„çŠ¶æ€ï¼Œè¿”å›çŠ¶æ€å¯¹è±¡ï¼›å¦åˆ™è¿”å›None
        """
        state = self.load_state()

        if not state:
            return None

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤
        if state.current_mission_index >= len(state.execution_order):
            logger.info("All missions completed, nothing to resume")
            return None

        logger.info(
            f"Resuming execution from mission {state.current_mission_index + 1}/"
            f"{len(state.execution_order)}"
        )

        return state
```

---

## 5ï¸âƒ£ èµ„æºéš”ç¦»ä¸æƒé™æ§åˆ¶

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- å·¥å…·æƒé™ç¼ºä¹é™åˆ¶ï¼Œæ‰€æœ‰è§’è‰²å¯è®¿é—®æ‰€æœ‰å·¥å…·
- MCPæœåŠ¡å™¨è¿æ¥æ— é€Ÿç‡é™åˆ¶ï¼Œå¯èƒ½è¢«æ»¥ç”¨
- ç¼ºä¹æ²™ç®±éš”ç¦»æœºåˆ¶

### è§£å†³æ–¹æ¡ˆ

#### 5.1 æœ€å°æƒé™å·¥å…·è®¿é—®

```python
# src/core/tools/permission_manager.py
from dataclasses import dataclass
from typing import List, Set
from enum import Enum

class ToolPermission(Enum):
    """å·¥å…·æƒé™"""
    READ_FILE = "read_file"
    WRITE_FILE = "write_file"
    DELETE_FILE = "delete_file"
    EXECUTE_COMMAND = "execute_command"
    WEB_SEARCH = "web_search"
    WEB_FETCH = "web_fetch"
    MCP_CALL = "mcp_call"

@dataclass
class ToolAccessPolicy:
    """å·¥å…·è®¿é—®ç­–ç•¥"""
    role_id: str
    allowed_tools: Set[str]
    allowed_permissions: Set[ToolPermission]
    denied_patterns: List[str]  # æ–‡ä»¶è·¯å¾„æ‹’ç»æ¨¡å¼ (å¦‚ "/etc/*", "~/.ssh/*")
    rate_limits: Dict[str, int]  # å·¥å…·é€Ÿç‡é™åˆ¶ (calls/minute)

class PermissionManager:
    """æƒé™ç®¡ç†å™¨"""

    def __init__(self):
        self.policies: Dict[str, ToolAccessPolicy] = {}

        # é»˜è®¤ç­–ç•¥ (æœ€å°æƒé™)
        self.default_policy = ToolAccessPolicy(
            role_id="default",
            allowed_tools={"read_file", "write_file"},
            allowed_permissions={
                ToolPermission.READ_FILE,
                ToolPermission.WRITE_FILE
            },
            denied_patterns=[
                "/etc/*",
                "~/.ssh/*",
                "~/.aws/*",
                "/root/*",
                "*.key",
                "*.pem"
            ],
            rate_limits={
                "web_search": 10,  # 10/min
                "mcp_call": 20     # 20/min
            }
        )

    def create_policy_from_role(self, role: dict) -> ToolAccessPolicy:
        """
        ä»è§’è‰²å®šä¹‰åˆ›å»ºè®¿é—®ç­–ç•¥

        åŸºäºè§’è‰²çš„ resources.tools å­—æ®µ
        """
        role_id = role["name"]
        allowed_tools = set(role.get("resources", {}).get("tools", []))

        # æ˜ å°„å·¥å…·åˆ°æƒé™
        permissions = set()
        for tool in allowed_tools:
            if tool in ["read_file", "glob", "grep"]:
                permissions.add(ToolPermission.READ_FILE)
            elif tool in ["write_file", "edit_file"]:
                permissions.add(ToolPermission.WRITE_FILE)
            elif tool in ["run_command", "bash"]:
                permissions.add(ToolPermission.EXECUTE_COMMAND)
            elif tool == "web_search":
                permissions.add(ToolPermission.WEB_SEARCH)
            elif tool == "web_fetch":
                permissions.add(ToolPermission.WEB_FETCH)

        # è§’è‰²ç‰¹å®šçš„æ‹’ç»æ¨¡å¼
        denied_patterns = self.default_policy.denied_patterns.copy()

        # å¼€å‘è€…è§’è‰²å¯èƒ½éœ€è¦æ›´å¤šæƒé™ï¼Œä½†ä»ç„¶æ‹’ç»æ•æ„Ÿè·¯å¾„
        if "developer" in role_id.lower():
            # å…è®¸æ›´å¤šè·¯å¾„ï¼Œä½†ä¿ç•™æ ¸å¿ƒå®‰å…¨é™åˆ¶
            denied_patterns = [p for p in denied_patterns if "/etc" in p or ".ssh" in p]

        policy = ToolAccessPolicy(
            role_id=role_id,
            allowed_tools=allowed_tools,
            allowed_permissions=permissions,
            denied_patterns=denied_patterns,
            rate_limits=self.default_policy.rate_limits.copy()
        )

        self.policies[role_id] = policy
        return policy

    def check_permission(
        self,
        role_id: str,
        tool_name: str,
        permission: ToolPermission,
        file_path: Optional[str] = None
    ) -> tuple[bool, str]:
        """
        æ£€æŸ¥æƒé™

        Returns:
            (allowed, reason)
        """
        policy = self.policies.get(role_id, self.default_policy)

        # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨
        if tool_name not in policy.allowed_tools:
            return False, f"Tool '{tool_name}' not allowed for role '{role_id}'"

        # æ£€æŸ¥æƒé™
        if permission not in policy.allowed_permissions:
            return False, f"Permission '{permission.value}' denied for role '{role_id}'"

        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ (å¦‚æœæä¾›)
        if file_path:
            import fnmatch
            for pattern in policy.denied_patterns:
                if fnmatch.fnmatch(file_path, pattern):
                    return False, f"Access to path '{file_path}' denied (pattern: '{pattern}')"

        return True, ""
```

#### 5.2 MCPé€Ÿç‡é™åˆ¶

```python
# src/core/tools/rate_limiter.py
from collections import defaultdict
from datetime import datetime, timedelta
from threading import Lock

class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""

    def __init__(self):
        self.call_history: Dict[str, List[datetime]] = defaultdict(list)
        self.lock = Lock()

    def check_rate_limit(
        self,
        role_id: str,
        tool_name: str,
        limit_per_minute: int
    ) -> tuple[bool, int]:
        """
        æ£€æŸ¥é€Ÿç‡é™åˆ¶

        Returns:
            (allowed, remaining_calls)
        """
        with self.lock:
            key = f"{role_id}:{tool_name}"
            now = datetime.utcnow()

            # æ¸…ç†1åˆ†é’Ÿå‰çš„è®°å½•
            self.call_history[key] = [
                ts for ts in self.call_history[key]
                if now - ts < timedelta(minutes=1)
            ]

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            current_calls = len(self.call_history[key])

            if current_calls >= limit_per_minute:
                return False, 0

            # è®°å½•æœ¬æ¬¡è°ƒç”¨
            self.call_history[key].append(now)

            remaining = limit_per_minute - current_calls - 1
            return True, remaining
```

---

## 6ï¸âƒ£ è§‚æµ‹ä¸è¿½è¸ª

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- ç¼ºä¹ç»Ÿä¸€çš„trace_idè¿½è¸ª
- æ—¥å¿—æ ¼å¼ä¸ç»Ÿä¸€ï¼Œéš¾ä»¥åˆ†æ
- æ— æ³•å…³è”ä»»åŠ¡ã€è§’è‰²ã€å¹²é¢„å†³ç­–çš„å®Œæ•´é“¾è·¯

### è§£å†³æ–¹æ¡ˆ

#### 6.1 ç»“æ„åŒ–è¿½è¸ªç³»ç»Ÿ

```python
# src/core/observability/structured_tracer.py
import uuid
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Optional, Dict, Any
import json
from pathlib import Path

@dataclass
class TraceSpan:
    """è¿½è¸ªspan"""
    trace_id: str          # å…¨å±€è¿½è¸ªID
    span_id: str           # å½“å‰span ID
    parent_span_id: Optional[str]  # çˆ¶span ID
    mission_id: Optional[str]
    role_id: Optional[str]
    operation: str         # æ“ä½œç±»å‹
    start_time: datetime
    end_time: Optional[datetime]
    duration_ms: Optional[float]
    status: str            # "running", "completed", "failed"
    metadata: Dict[str, Any]
    cost_usd: float
    tokens_used: int
    tags: Dict[str, str]

class StructuredTracer:
    """ç»“æ„åŒ–è¿½è¸ªå™¨"""

    def __init__(self, trace_dir: Path):
        self.trace_dir = trace_dir
        self.trace_dir.mkdir(parents=True, exist_ok=True)

        # å½“å‰traceä¸Šä¸‹æ–‡
        self.current_trace_id: Optional[str] = None
        self.span_stack: List[TraceSpan] = []

    def start_trace(self, session_id: str) -> str:
        """å¼€å§‹æ–°çš„è¿½è¸ª"""
        self.current_trace_id = f"trace-{uuid.uuid4().hex[:16]}"

        logger.info(
            f"Started trace: {self.current_trace_id} (session: {session_id})"
        )

        return self.current_trace_id

    def start_span(
        self,
        operation: str,
        mission_id: Optional[str] = None,
        role_id: Optional[str] = None,
        **metadata
    ) -> str:
        """å¼€å§‹æ–°çš„span"""
        span_id = f"span-{uuid.uuid4().hex[:12]}"
        parent_span_id = self.span_stack[-1].span_id if self.span_stack else None

        span = TraceSpan(
            trace_id=self.current_trace_id,
            span_id=span_id,
            parent_span_id=parent_span_id,
            mission_id=mission_id,
            role_id=role_id,
            operation=operation,
            start_time=datetime.utcnow(),
            end_time=None,
            duration_ms=None,
            status="running",
            metadata=metadata,
            cost_usd=0.0,
            tokens_used=0,
            tags={}
        )

        self.span_stack.append(span)

        # å®æ—¶å†™å…¥ (streaming trace)
        self._write_span_event(span, "start")

        return span_id

    def end_span(
        self,
        status: str = "completed",
        cost_usd: float = 0.0,
        tokens_used: int = 0,
        **metadata
    ):
        """ç»“æŸå½“å‰span"""
        if not self.span_stack:
            return

        span = self.span_stack.pop()
        span.end_time = datetime.utcnow()
        span.duration_ms = (span.end_time - span.start_time).total_seconds() * 1000
        span.status = status
        span.cost_usd = cost_usd
        span.tokens_used = tokens_used
        span.metadata.update(metadata)

        # å†™å…¥å®Œæˆäº‹ä»¶
        self._write_span_event(span, "end")

    def add_span_tag(self, key: str, value: str):
        """æ·»åŠ spanæ ‡ç­¾"""
        if self.span_stack:
            self.span_stack[-1].tags[key] = value

    def _write_span_event(self, span: TraceSpan, event_type: str):
        """å†™å…¥spanäº‹ä»¶ (JSONLæ ¼å¼)"""
        trace_file = self.trace_dir / f"{self.current_trace_id}.jsonl"

        event = {
            "event_type": event_type,
            "timestamp": datetime.utcnow().isoformat(),
            **asdict(span)
        }

        # åºåˆ—åŒ–datetime
        event["start_time"] = span.start_time.isoformat()
        if span.end_time:
            event["end_time"] = span.end_time.isoformat()

        # è¿½åŠ åˆ°JSONL
        with open(trace_file, 'a') as f:
            f.write(json.dumps(event, ensure_ascii=False) + '\n')

    def query_spans(
        self,
        trace_id: str,
        mission_id: Optional[str] = None,
        role_id: Optional[str] = None,
        operation: Optional[str] = None
    ) -> List[TraceSpan]:
        """æŸ¥è¯¢spans"""
        trace_file = self.trace_dir / f"{trace_id}.jsonl"

        if not trace_file.exists():
            return []

        spans = []
        with open(trace_file) as f:
            for line in f:
                event = json.loads(line)
                if event["event_type"] == "end":  # åªå–å®Œæˆçš„span
                    # è¿‡æ»¤æ¡ä»¶
                    if mission_id and event["mission_id"] != mission_id:
                        continue
                    if role_id and event["role_id"] != role_id:
                        continue
                    if operation and event["operation"] != operation:
                        continue

                    spans.append(event)

        return spans
```

#### 6.2 ç»“æ„åŒ–æ—¥å¿—

```python
# src/core/observability/structured_logger.py
import logging
import json
from datetime import datetime
from typing import Optional

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—å™¨"""

    def __init__(self, log_file: Path):
        self.log_file = log_file

        # é…ç½®JSONæ—¥å¿—handler
        self.logger = logging.getLogger("structured")
        self.logger.setLevel(logging.INFO)

        handler = logging.FileHandler(log_file)
        handler.setFormatter(logging.Formatter('%(message)s'))
        self.logger.addHandler(handler)

    def log(
        self,
        level: str,
        message: str,
        trace_id: Optional[str] = None,
        span_id: Optional[str] = None,
        mission_id: Optional[str] = None,
        role_id: Optional[str] = None,
        **extra
    ):
        """è®°å½•ç»“æ„åŒ–æ—¥å¿—"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": level.upper(),
            "message": message,
            "trace_id": trace_id,
            "span_id": span_id,
            "mission_id": mission_id,
            "role_id": role_id,
            **extra
        }

        self.logger.info(json.dumps(log_entry, ensure_ascii=False))

    def log_intervention(
        self,
        trace_id: str,
        mission_id: str,
        role_id: str,
        action: str,
        reason: str,
        score: float,
        cost_usd: float,
        **extra
    ):
        """è®°å½•å¹²é¢„å†³ç­–"""
        self.log(
            level="INFO",
            message=f"Leader intervention: {action}",
            trace_id=trace_id,
            mission_id=mission_id,
            role_id=role_id,
            event_type="intervention",
            action=action,
            reason=reason,
            quality_score=score,
            cost_usd=cost_usd,
            **extra
        )
```

---

## 7ï¸âƒ£ ç»ˆæ€ç­–ç•¥ä¸æ¢å¤æŒ‡å—

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- é¢„ç®—è¶…é™/ä»»åŠ¡å¤±è´¥æ—¶ç›´æ¥ç»ˆæ­¢ï¼Œç¼ºä¹éƒ¨åˆ†äº¤ä»˜
- æ²¡æœ‰æ®‹ä½™é£é™©æŠ¥å‘Šå’Œæ¢å¤æŒ‡å—
- ç¼ºä¹ä¸€è‡´æ€§æ£€æŸ¥æœºåˆ¶

### è§£å†³æ–¹æ¡ˆ

#### 7.1 éƒ¨åˆ†äº¤ä»˜å¤„ç†

```python
# src/core/termination/partial_delivery.py
from dataclasses import dataclass
from typing import List, Dict, Any
from pathlib import Path
import json

@dataclass
class PartialDeliverable:
    """éƒ¨åˆ†äº¤ä»˜ç‰©"""
    completed_missions: List[str]
    incomplete_missions: List[str]
    deliverables: Dict[str, List[str]]  # mission_id -> file paths
    quality_scores: Dict[str, float]
    total_cost_usd: float
    completion_ratio: float  # 0.0 - 1.0

@dataclass
class ResidualRisk:
    """æ®‹ä½™é£é™©"""
    risk_type: str  # "incomplete", "low_quality", "untested"
    severity: str   # "low", "medium", "high", "critical"
    affected_missions: List[str]
    description: str
    mitigation: str

@dataclass
class RecoveryGuide:
    """æ¢å¤æŒ‡å—"""
    termination_reason: str
    checkpoint_path: str
    resume_from_mission: str
    required_actions: List[str]
    estimated_cost_to_complete: float
    estimated_time_minutes: int

class PartialDeliveryHandler:
    """éƒ¨åˆ†äº¤ä»˜å¤„ç†å™¨"""

    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_partial_delivery(
        self,
        execution_state: TeamExecutionState,
        termination_reason: str
    ) -> PartialDeliverable:
        """ç”Ÿæˆéƒ¨åˆ†äº¤ä»˜ç‰©"""
        completed = execution_state.completed_missions
        incomplete = [
            mid for mid in execution_state.execution_order
            if mid not in completed
        ]

        deliverables = {}
        quality_scores = {}

        for mission_id in completed:
            mission_state = execution_state.mission_states.get(mission_id)
            if mission_state:
                deliverables[mission_id] = mission_state.outputs
                quality_scores[mission_id] = self._get_quality_score(mission_id)

        completion_ratio = len(completed) / len(execution_state.execution_order)

        partial = PartialDeliverable(
            completed_missions=completed,
            incomplete_missions=incomplete,
            deliverables=deliverables,
            quality_scores=quality_scores,
            total_cost_usd=execution_state.total_cost_usd,
            completion_ratio=completion_ratio
        )

        # ä¿å­˜éƒ¨åˆ†äº¤ä»˜è¯´æ˜
        self._save_partial_delivery_doc(partial, termination_reason)

        return partial

    def analyze_residual_risks(
        self,
        partial: PartialDeliverable
    ) -> List[ResidualRisk]:
        """åˆ†ææ®‹ä½™é£é™©"""
        risks = []

        # é£é™©1: æœªå®Œæˆçš„ä»»åŠ¡
        if partial.incomplete_missions:
            risks.append(ResidualRisk(
                risk_type="incomplete",
                severity="high" if partial.completion_ratio < 0.5 else "medium",
                affected_missions=partial.incomplete_missions,
                description=f"{len(partial.incomplete_missions)} missions not completed",
                mitigation="Resume execution from checkpoint or manually complete tasks"
            ))

        # é£é™©2: ä½è´¨é‡äº¤ä»˜
        low_quality_missions = [
            mid for mid, score in partial.quality_scores.items()
            if score < 70.0
        ]
        if low_quality_missions:
            risks.append(ResidualRisk(
                risk_type="low_quality",
                severity="medium",
                affected_missions=low_quality_missions,
                description=f"{len(low_quality_missions)} missions have quality < 70%",
                mitigation="Review and improve deliverables manually"
            ))

        # é£é™©3: æœªç»æµ‹è¯• (æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ–‡ä»¶)
        untested_missions = [
            mid for mid in partial.completed_missions
            if not self._has_tests(partial.deliverables.get(mid, []))
        ]
        if untested_missions:
            risks.append(ResidualRisk(
                risk_type="untested",
                severity="high",
                affected_missions=untested_missions,
                description=f"{len(untested_missions)} missions lack test coverage",
                mitigation="Add tests before deployment"
            ))

        return risks

    def generate_recovery_guide(
        self,
        execution_state: TeamExecutionState,
        termination_reason: str,
        partial: PartialDeliverable
    ) -> RecoveryGuide:
        """ç”Ÿæˆæ¢å¤æŒ‡å—"""
        resume_mission = (
            partial.incomplete_missions[0]
            if partial.incomplete_missions
            else None
        )

        required_actions = []

        if "budget" in termination_reason.lower():
            required_actions.append("Increase budget allocation")
            required_actions.append(f"Current cost: ${partial.total_cost_usd:.2f}")

        if "quality" in termination_reason.lower():
            required_actions.append("Review quality thresholds")
            required_actions.append("Consider enhancing task definitions")

        required_actions.append(f"Resume from mission: {resume_mission}")

        # ä¼°ç®—å®Œæˆæˆæœ¬
        avg_cost_per_mission = partial.total_cost_usd / max(len(partial.completed_missions), 1)
        estimated_cost = avg_cost_per_mission * len(partial.incomplete_missions)

        guide = RecoveryGuide(
            termination_reason=termination_reason,
            checkpoint_path=str(execution_state.state_file),
            resume_from_mission=resume_mission,
            required_actions=required_actions,
            estimated_cost_to_complete=estimated_cost,
            estimated_time_minutes=len(partial.incomplete_missions) * 30  # ä¼°ç®—
        )

        self._save_recovery_guide(guide)

        return guide

    def _save_partial_delivery_doc(
        self,
        partial: PartialDeliverable,
        reason: str
    ):
        """ä¿å­˜éƒ¨åˆ†äº¤ä»˜è¯´æ˜æ–‡æ¡£"""
        doc_path = self.output_dir / "PARTIAL_DELIVERY.md"

        content = f"""# Partial Delivery Report

## Termination Reason
{reason}

## Completion Status
- **Completion Ratio**: {partial.completion_ratio:.1%}
- **Completed Missions**: {len(partial.completed_missions)}
- **Incomplete Missions**: {len(partial.incomplete_missions)}
- **Total Cost**: ${partial.total_cost_usd:.2f}

## Completed Missions

"""

        for mission_id in partial.completed_missions:
            quality = partial.quality_scores.get(mission_id, 0.0)
            files = partial.deliverables.get(mission_id, [])

            content += f"""### {mission_id}
- **Quality Score**: {quality:.1f}/100
- **Deliverables** ({len(files)} files):
"""
            for file_path in files:
                content += f"  - `{file_path}`\n"
            content += "\n"

        content += f"""## Incomplete Missions

"""
        for mission_id in partial.incomplete_missions:
            content += f"- {mission_id}\n"

        with open(doc_path, 'w') as f:
            f.write(content)

    def _save_recovery_guide(self, guide: RecoveryGuide):
        """ä¿å­˜æ¢å¤æŒ‡å—"""
        guide_path = self.output_dir / "RECOVERY_GUIDE.md"

        content = f"""# Recovery Guide

## Termination Reason
{guide.termination_reason}

## Checkpoint Information
- **Checkpoint Path**: `{guide.checkpoint_path}`
- **Resume From Mission**: `{guide.resume_from_mission}`

## Required Actions

"""
        for action in guide.required_actions:
            content += f"- [ ] {action}\n"

        content += f"""
## Estimated Resources to Complete
- **Cost**: ${guide.estimated_cost_to_complete:.2f}
- **Time**: ~{guide.estimated_time_minutes} minutes

## How to Resume

1. Review the required actions above
2. Update configuration if needed (budget, thresholds, etc.)
3. Run the following command:

```bash
python -m src.main --resume {guide.checkpoint_path}
```

## Support
For assistance, contact the team or check logs in `logs/` directory.
"""

        with open(guide_path, 'w') as f:
            f.write(content)
```

---

## 8ï¸âƒ£ è¾…åŠ©è§’è‰²æ²»ç†

### é—®é¢˜åˆ†æ

**å½“å‰é—®é¢˜**ï¼š
- AddHelperå¯èƒ½æ— é™æ·»åŠ è¾…åŠ©è§’è‰²ï¼Œå¯¼è‡´æˆæœ¬å¤±æ§
- ç¼ºä¹é€€åœºæ¡ä»¶ï¼Œè¾…åŠ©è§’è‰²å¯èƒ½é•¿æœŸå ç”¨èµ„æº
- é‡è¯•ç­–ç•¥ç¼ºä¹é€€é¿æœºåˆ¶

### è§£å†³æ–¹æ¡ˆ

#### 8.1 è¾…åŠ©è§’è‰²ç®¡ç†

```python
# src/core/intervention/helper_governance.py
from dataclasses import dataclass
from typing import List, Optional
from enum import Enum

class HelperExitCondition(Enum):
    """è¾…åŠ©è§’è‰²é€€åœºæ¡ä»¶"""
    TASK_COMPLETED = "task_completed"
    QUALITY_THRESHOLD_MET = "quality_met"
    MAX_ITERATIONS = "max_iterations"
    BUDGET_EXHAUSTED = "budget_exhausted"
    REDUNDANT = "redundant"  # ä¸ä¸»è§’è‰²é‡å¤

@dataclass
class HelperRole:
    """è¾…åŠ©è§’è‰²"""
    helper_id: str
    role_name: str
    parent_mission_id: str
    assigned_task: str
    max_iterations: int
    current_iteration: int
    budget_allocation: BudgetAllocation
    exit_conditions: List[HelperExitCondition]
    quality_threshold: float

class HelperGovernor:
    """è¾…åŠ©è§’è‰²æ²»ç†å™¨"""

    def __init__(
        self,
        max_helpers_per_mission: int = 2,
        max_total_helpers: int = 5
    ):
        self.max_helpers_per_mission = max_helpers_per_mission
        self.max_total_helpers = max_total_helpers

        self.active_helpers: Dict[str, HelperRole] = {}
        self.helpers_by_mission: Dict[str, List[str]] = defaultdict(list)

    def can_add_helper(
        self,
        mission_id: str
    ) -> tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦å¯ä»¥æ·»åŠ è¾…åŠ©è§’è‰²

        Returns:
            (allowed, reason)
        """
        # æ£€æŸ¥æ€»æ•°é™åˆ¶
        if len(self.active_helpers) >= self.max_total_helpers:
            return False, f"Max total helpers reached ({self.max_total_helpers})"

        # æ£€æŸ¥ä»»åŠ¡çº§é™åˆ¶
        mission_helpers = self.helpers_by_mission.get(mission_id, [])
        if len(mission_helpers) >= self.max_helpers_per_mission:
            return False, f"Max helpers per mission reached ({self.max_helpers_per_mission})"

        return True, ""

    def add_helper(
        self,
        mission_id: str,
        role_name: str,
        task: str,
        budget: BudgetAllocation
    ) -> HelperRole:
        """æ·»åŠ è¾…åŠ©è§’è‰²"""
        helper_id = f"helper-{uuid.uuid4().hex[:8]}"

        helper = HelperRole(
            helper_id=helper_id,
            role_name=role_name,
            parent_mission_id=mission_id,
            assigned_task=task,
            max_iterations=3,  # è¾…åŠ©è§’è‰²é™åˆ¶æ›´ä¸¥æ ¼
            current_iteration=0,
            budget_allocation=budget,
            exit_conditions=[
                HelperExitCondition.QUALITY_THRESHOLD_MET,
                HelperExitCondition.MAX_ITERATIONS,
                HelperExitCondition.BUDGET_EXHAUSTED
            ],
            quality_threshold=80.0  # è¾…åŠ©è§’è‰²è¦æ±‚æ›´é«˜è´¨é‡
        )

        self.active_helpers[helper_id] = helper
        self.helpers_by_mission[mission_id].append(helper_id)

        logger.info(
            f"Added helper {helper_id} ({role_name}) for mission {mission_id}"
        )

        return helper

    def should_exit_helper(
        self,
        helper_id: str,
        quality_score: float,
        is_redundant: bool = False
    ) -> tuple[bool, HelperExitCondition]:
        """
        æ£€æŸ¥è¾…åŠ©è§’è‰²æ˜¯å¦åº”è¯¥é€€åœº

        Returns:
            (should_exit, exit_condition)
        """
        helper = self.active_helpers.get(helper_id)
        if not helper:
            return False, None

        # æ£€æŸ¥è´¨é‡é˜ˆå€¼
        if (HelperExitCondition.QUALITY_THRESHOLD_MET in helper.exit_conditions and
            quality_score >= helper.quality_threshold):
            return True, HelperExitCondition.QUALITY_THRESHOLD_MET

        # æ£€æŸ¥è¿­ä»£æ¬¡æ•°
        if (HelperExitCondition.MAX_ITERATIONS in helper.exit_conditions and
            helper.current_iteration >= helper.max_iterations):
            return True, HelperExitCondition.MAX_ITERATIONS

        # æ£€æŸ¥é¢„ç®—
        budget_status, _ = budget_controller.check_budget(helper_id)
        if (HelperExitCondition.BUDGET_EXHAUSTED in helper.exit_conditions and
            budget_status in ["critical", "exceeded"]):
            return True, HelperExitCondition.BUDGET_EXHAUSTED

        # æ£€æŸ¥å†—ä½™
        if (HelperExitCondition.REDUNDANT in helper.exit_conditions and
            is_redundant):
            return True, HelperExitCondition.REDUNDANT

        return False, None

    def remove_helper(
        self,
        helper_id: str,
        exit_condition: HelperExitCondition
    ):
        """ç§»é™¤è¾…åŠ©è§’è‰²"""
        helper = self.active_helpers.get(helper_id)
        if not helper:
            return

        mission_id = helper.parent_mission_id

        del self.active_helpers[helper_id]
        self.helpers_by_mission[mission_id].remove(helper_id)

        logger.info(
            f"Removed helper {helper_id} from mission {mission_id} "
            f"(reason: {exit_condition.value})"
        )
```

#### 8.2 é€€é¿ç­–ç•¥

```python
# src/core/intervention/backoff_strategy.py
import time
from enum import Enum
from typing import Callable

class BackoffStrategy(Enum):
    """é€€é¿ç­–ç•¥"""
    LINEAR = "linear"
    EXPONENTIAL = "exponential"
    FIBONACCI = "fibonacci"

class RetryBackoff:
    """é‡è¯•é€€é¿å™¨"""

    def __init__(
        self,
        strategy: BackoffStrategy = BackoffStrategy.EXPONENTIAL,
        base_delay_seconds: float = 2.0,
        max_delay_seconds: float = 60.0
    ):
        self.strategy = strategy
        self.base_delay = base_delay_seconds
        self.max_delay = max_delay_seconds

    def get_delay(self, attempt: int) -> float:
        """
        è·å–å»¶è¿Ÿæ—¶é—´ (ç§’)

        Args:
            attempt: é‡è¯•æ¬¡æ•° (1-based)
        """
        if self.strategy == BackoffStrategy.LINEAR:
            delay = self.base_delay * attempt

        elif self.strategy == BackoffStrategy.EXPONENTIAL:
            delay = self.base_delay * (2 ** (attempt - 1))

        elif self.strategy == BackoffStrategy.FIBONACCI:
            delay = self.base_delay * self._fibonacci(attempt)

        else:
            delay = self.base_delay

        return min(delay, self.max_delay)

    def _fibonacci(self, n: int) -> int:
        """è®¡ç®—æ–æ³¢é‚£å¥‘æ•°"""
        if n <= 1:
            return 1
        a, b = 1, 1
        for _ in range(n - 1):
            a, b = b, a + b
        return a

    async def retry_with_backoff(
        self,
        func: Callable,
        max_retries: int,
        *args,
        **kwargs
    ):
        """
        å¸¦é€€é¿çš„é‡è¯•

        Example:
            result = await backoff.retry_with_backoff(
                execute_role,
                max_retries=3,
                mission=mission,
                role=role
            )
        """
        for attempt in range(1, max_retries + 1):
            try:
                result = await func(*args, **kwargs)
                return result

            except Exception as e:
                if attempt == max_retries:
                    raise e

                delay = self.get_delay(attempt)
                logger.warning(
                    f"Retry attempt {attempt}/{max_retries} failed: {e}. "
                    f"Retrying in {delay:.1f}s..."
                )

                time.sleep(delay)
```

---

## ğŸ“Š å®æ–½ä¼˜å…ˆçº§ä¸è·¯çº¿å›¾

### Phase 1 (P0 - ç«‹å³å®æ–½)

**ç›®æ ‡**: å…³é”®å¥å£®æ€§å¢å¼º

1. **ç»“æ„åŒ–åè®®** (1å‘¨)
   - SubMission Schemaå®šä¹‰
   - ExecutionContext Schema
   - SchemaValidatorå®ç°

2. **å¤šç»´åº¦è¯„ä¼°** (1å‘¨)
   - MultiDimEvaluatoræ¡†æ¶
   - æµ‹è¯•ç»´åº¦é›†æˆ
   - é™æ€æ£€æŸ¥ç»´åº¦

3. **åˆ†å±‚é¢„ç®—æ§åˆ¶** (1å‘¨)
   - HierarchicalBudgetController
   - CircuitBreakerå®ç°
   - åŠ¨æ€é¢„ç®—åˆ†é…

4. **ç»“æ„åŒ–è¿½è¸ª** (1å‘¨)
   - StructuredTracerå®ç°
   - TraceSpanè®¾è®¡
   - JSONLè¿½è¸ªæ—¥å¿—

### Phase 2 (P1 - è¿‘æœŸå®æ–½)

**ç›®æ ‡**: å¯æ¢å¤æ€§å’Œèµ„æºæ²»ç†

1. **å¹‚ç­‰ä¸æ¢å¤** (1.5å‘¨)
   - IdempotentExecutor
   - ExecutionStateManager
   - æ–­ç‚¹ç»­è·‘åŠŸèƒ½

2. **èµ„æºéš”ç¦»** (1å‘¨)
   - PermissionManager
   - æœ€å°æƒé™å·¥å…·è®¿é—®
   - MCPé€Ÿç‡é™åˆ¶

3. **è¾…åŠ©è§’è‰²æ²»ç†** (1å‘¨)
   - HelperGovernor
   - é€€åœºæ¡ä»¶å®ç°
   - RetryBackoffç­–ç•¥

### Phase 3 (P2 - åç»­ä¼˜åŒ–)

**ç›®æ ‡**: ç”¨æˆ·ä½“éªŒå’Œå¯è§‚æµ‹æ€§

1. **ç»ˆæ€ç­–ç•¥** (1å‘¨)
   - PartialDeliveryHandler
   - ResidualRiskåˆ†æ
   - RecoveryGuideç”Ÿæˆ

2. **å¯è§‚æµ‹æ€§å¢å¼º** (1å‘¨)
   - è¿½è¸ªæŸ¥è¯¢API
   - å¯è§†åŒ–Dashboard
   - å‘Šè­¦ç³»ç»Ÿ

3. **æ–‡æ¡£å’Œæµ‹è¯•** (1å‘¨)
   - APIæ–‡æ¡£
   - é›†æˆæµ‹è¯•
   - æ€§èƒ½æµ‹è¯•

---

## âœ… éªŒæ”¶æ ‡å‡†

### ç»“æ„åŒ–åè®®
- [ ] æ‰€æœ‰SubMissioné€šè¿‡SchemaéªŒè¯
- [ ] Contextä¼ é€’å“ˆå¸ŒéªŒè¯é€šè¿‡ç‡ 100%
- [ ] ç‰ˆæœ¬åŒ–æœºåˆ¶å¯è¿½æº¯æ‰€æœ‰å˜æ›´

### è¯„ä¼°å¼ºåŒ–
- [ ] å¤šç»´åº¦è¯„ä¼°è¦†ç›–æ‰€æœ‰è§’è‰²
- [ ] æµ‹è¯•ç»´åº¦è¦†ç›–ç‡ â‰¥ 80%
- [ ] è¯„ä¼°ç»“æœå¯é‡æ”¾ï¼Œè¯¯å·® < 5%

### æˆæœ¬ä¸èŠ‚æµ
- [ ] é¢„ç®—æ§åˆ¶å‡†ç¡®ç‡ 100%
- [ ] ç†”æ–­å™¨å“åº”æ—¶é—´ < 1ç§’
- [ ] ä¼˜å…ˆçº§é™çº§ç­–ç•¥æœ‰æ•ˆ

### å¹‚ç­‰ä¸æ¢å¤
- [ ] å¹‚ç­‰æ€§æµ‹è¯•é€šè¿‡ç‡ 100%
- [ ] æ–­ç‚¹ç»­è·‘æˆåŠŸç‡ â‰¥ 95%
- [ ] çŠ¶æ€æŒä¹…åŒ–é›¶æ•°æ®ä¸¢å¤±

### èµ„æºéš”ç¦»
- [ ] æƒé™è¿è§„æ£€æµ‹ç‡ 100%
- [ ] MCPé€Ÿç‡é™åˆ¶å‡†ç¡®
- [ ] æ•æ„Ÿè·¯å¾„è®¿é—®æ‹¦æˆªç‡ 100%

### è§‚æµ‹ä¸è¿½è¸ª
- [ ] æ‰€æœ‰æ“ä½œæœ‰trace_id
- [ ] è¿½è¸ªé“¾è·¯å®Œæ•´æ€§ 100%
- [ ] æ—¥å¿—æŸ¥è¯¢å“åº”æ—¶é—´ < 500ms

### ç»ˆæ€ç­–ç•¥
- [ ] éƒ¨åˆ†äº¤ä»˜ç”ŸæˆæˆåŠŸç‡ 100%
- [ ] æ¢å¤æŒ‡å—å‡†ç¡®æ€§ â‰¥ 90%
- [ ] ä¸€è‡´æ€§æ£€æŸ¥è¦†ç›–æ‰€æœ‰åœºæ™¯

### è¾…åŠ©è§’è‰²æ²»ç†
- [ ] è¾…åŠ©è§’è‰²æ•°é‡é™åˆ¶æœ‰æ•ˆ
- [ ] é€€åœºæ¡ä»¶è§¦å‘å‡†ç¡®
- [ ] é€€é¿ç­–ç•¥ç¬¦åˆé¢„æœŸ

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **æ¶æ„é‡æ„æ–¹æ¡ˆ**: `docs/Architecture-Refactor-v4.0.md`
- **å·¥ä½œæµç¨‹å›¾**: `AI-Native-Team-Workflow.md`
- **ç‰ˆæœ¬å†å²**: `CHANGELOG.md`

---

**æ–‡æ¡£ç‰ˆæœ¬**: v4.1-enhancements
**åˆ›å»ºæ—¥æœŸ**: 2025-01-22
**çŠ¶æ€**: è®¾è®¡å®Œæˆï¼Œå¾…å®æ–½
